{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üê∏ <span style='color :#40be46' > JFrog Swampup 2024 MLOPs LAB - The Frog-Factor Authenticator </span> üê∏ \n",
        "\n",
        "Welcome to the Lab! \n",
        "\n",
        "\n",
        "At JFrog, we're always exploring new features and capabilities. Today, we're diving into the authentication market with a brilliant idea: the \"Frog-Factor\" authenticator. This unique tool will authenticate you by recognizing your face alongside the JFrog frog in the same photo!\n",
        "\n",
        "Your mission, if you choose to accept it, is to help us build the Frog-Factor authenticator.\n",
        "\n",
        "First up, we'll need an object-detection model to get us started. Fortunately, we don't have to start from scratch! There are existing models we can use. But will they work out of the box? And remember, we must develop this authenticator securely and reliably.\n",
        "\n",
        "As you work through the notebook, follow the cells in order:\n",
        "\n",
        "‚ú® - This icon means there's a task for you to complete before moving to the next cell.\n",
        "\n",
        "üëÄ - This icon provides information about what the next cell is doing.\n",
        "\n",
        "Let's get started! We're here to help you every step of the way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K28AUog3BKoM"
      },
      "source": [
        "# <span style='color :#40be46' > Let's prepare the environment </span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M21zzwRBKoN"
      },
      "source": [
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "Since we want to work in a secure and trusted way, we will use Artifactory to store both the model as well as all the python dependencies that will be used during the process. \n",
        "\n",
        "Please perform the following steps:\n",
        "1. Log in to the training Artifactory here: https://jftrain17224572670.jfrog.io/\n",
        "2. From the projects dropdown list, select your project (\"mlops-userx\")\n",
        "3. Navigate to *Administration --> Repositories*.\n",
        "4. Click on 'Create a Repository' and select *Remote*. Select *HuggingFaceML* .\n",
        "5. In the next page, only provide the *Repository Key* (the repo name)  **The repository will be prefixed with your project name (\"mlops-userx\"). Please add the repository key \"hf-remote\"**  then click `Create Remote Repository`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkYprO9zBKoY"
      },
      "source": [
        "# üê∏  <span style='color :#40be46' > Lab1: Caching HuggingFace models in Artifactory </span> üê∏ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQFU8IDvBKoY"
      },
      "source": [
        "## Configure HuggingFace client to work through Artifactory\n",
        "\n",
        "We don't have to start from scratch! Luckily HuggingFace contains some great object detection models we can try out. \n",
        "Since we want to store the models in Artifactory, we'll need to configure the environment as follows.\n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "Please open your Artifactory instance and navigate to your newly created *remote HuggingFaceML* repository and click on \"Set Me Up\" in the top bar on the right.\n",
        "1. Copy the *token* and paste it in the cell below, replacing the \\<IDENTITY_TOKEN> placeholder \n",
        "2. Replace x (in *userx-hf-remote* inside the HF_ENDPOINT env var) with your lab studentId number\n",
        "\n",
        "üëÄ The next cell sets the environment variables such that the huggingface client which we'll use later will not fetch the model from the hugging_face hub, but rather from Artifactory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWHO4UF2BKoZ",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Replace the <IDENTITY-TOKEN> placeholder with the token you generated in the JFrog Platform SetMeUp.\n",
        "%env HF_TOKEN=<IDENTITY-TOKEN>\n",
        "\n",
        "# Replace x (in userx-hf-remote) with your userid number\n",
        "%env HF_ENDPOINT=https://jftrain17224572670.jfrog.io/artifactory/mlops-userx-hf-remote/\n",
        "\n",
        "%env HF_HUB_ETAG_TIMEOUT=86400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB36qj04BKoZ"
      },
      "source": [
        "## Download the required Python packages through Artifactory\n",
        "\n",
        "To use and test our model, we'll need some python packages. Since we want to make sure we're using trusted and allowed packages, we'll get the packages also from Artifactory.\n",
        "We'll configure the python installations to go to Artifactory to fetch the packages. \n",
        "\n",
        "We've already configured a pypi repository for you to use. Run the next cell to download the required dependencies. \n",
        "\n",
        "*NOTE:*\n",
        "The following cell may take up to 3 minutes to complete. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "1. In Artifactory,go to our pypi repository: https://jftrain17224572670.jfrog.io/ui/repos/tree/General/mlops-training-remote-pypi \n",
        "2. Click on `Set Me Up` in the top bar, and click on `Install` tab.\n",
        "3. Copy the URL from the value of index-url (should look something like https://youruser:<PASSWORD>@jftrain17224572670.jfrog.io/artifactory/api/pypi/mlops-training-remote-pypi/simple)\n",
        "4. Replace \\<ARTIFACTORY_PIP_REPOSITORY_URL> with the URL you copied .\n",
        "\n",
        "\n",
        "*NOTE:*\n",
        "The following cell may take up to 3 minutes to complete. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JevGqh2tBKoZ",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Replace <ARTIFACTORY_PIP_REPOSITORY_URL> with the URL pointing to your pip repository found in the the JFrog Platform Set-Me-Up.\n",
        "!pip3 install huggingface_hub ultralytics -i <ARTIFACTORY_PIP_REPOSITORY_URL>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vu_iqU8BKoZ"
      },
      "source": [
        "## Python imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ0tV1EBBKoZ",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download, HfApi\n",
        "from huggingface_hub.utils import HfHubHTTPError\n",
        "\n",
        "import json\n",
        "import random\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import cv2\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import logging,shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x1XYVieBKoZ"
      },
      "source": [
        "## Download the pre-trained model\n",
        "\n",
        "üëÄ We'll be using the Yolov8 object detection pre-trained model. It's initially configured only to detect human faces.\n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "Replace \\<YOUR_NAME> with your name. Don't forget to surround it by quote e.g. \"Tom\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xk2YsfWBKoZ",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the model and processor\n",
        "model_name = \"shirabendor/YOLOV8-oiv7\"\n",
        "weights = \"yolov8m-oiv7.pt\"\n",
        "config_file = \"./model/main/config.json\"\n",
        "name = \"<YOUR_NAME>\"\n",
        "\n",
        "try:\n",
        "    snapshot_download(repo_id=model_name, allow_patterns=[weights, \"mlops.zip\"], local_dir=\".\")\n",
        "except HfHubHTTPError as e:\n",
        "    print(\"\\n\\n\\U0001F6A8\\U0001F6A8\\U0001F6A8\\U0001F6A8 Xray blocked model download due to violation of the `Block Malicious Packages` policy.\\U0001F6A8\\U0001F6A8\\U0001F6A8\\U0001F6A8\\n\\n\")\n",
        "\n",
        "# unpack the other course materials and remove the default folder by colab\n",
        "!unzip mlops.zip\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJiHbu-qBKoa"
      },
      "source": [
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "Let's check Artifactory to review the outcome.\n",
        "\n",
        "Please open your Artifactory instance and navigate to your newly created *remote HuggingfaceML repository*\n",
        "\n",
        "Here is a direct link (replace x with your studentID):  https://jftrain17224572670.jfrog.io/artifactory/mlops-userx-hf-remote/\n",
        "\n",
        "Expect to see something similar to the following:\n",
        "\n",
        "![image.png](./model/main/img/repo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6fNTSzMBKoa"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "üëÄ The following cell defines some helper functions that will help us to test and develop the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isp8HlzUBKoa"
      },
      "outputs": [],
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC04jdmPBKoa"
      },
      "source": [
        "# Inference function\n",
        "\n",
        "üëÄ The following cell defines the inference function. The \"predict\" function will get an image as input, and try to detect human face in the image. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jbrhBqNBKoa",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "logging.getLogger(\"ultralytics\").setLevel(logging.ERROR) \n",
        "\n",
        "model = YOLO(weights)\n",
        "\n",
        "def infere(cheat=False, name=name):\n",
        "    \n",
        "    with open(config_file, 'r') as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    classes        = config['classes']\n",
        "    target_classes = config['target_classes']\n",
        "    conf           = config['conf']\n",
        "    max_det        = config['max_det']\n",
        "\n",
        "    filename = 'photo.jpg'  # Default filename\n",
        "    if not cheat:\n",
        "        filename = take_photo()\n",
        "    else:\n",
        "      data = \"./model/main/img/tom.jpg\"\n",
        "      name = \"Tom Hanks\"\n",
        "      shutil.copy(data, filename)\n",
        "           \n",
        "\n",
        "    frame = cv2.imread(filename) \n",
        "\n",
        "    frame_height, frame_width = frame.shape[:2]\n",
        "    results = model.predict(source=frame, \n",
        "                            show=False, \n",
        "                            classes=classes, \n",
        "                            conf=conf,\n",
        "                            max_det=max_det)\n",
        "\n",
        "    # Extracting the names of detected classes\n",
        "    boxes = results[0].boxes\n",
        "\n",
        "     # Draw bounding boxes\n",
        "    for box in boxes:\n",
        "        label = model.names[int(box.cls)]\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Convert to integer coordinates\n",
        "  \n",
        "        if int(box.cls) in target_classes:\n",
        "          # Draw bounding box around detected object\n",
        "          cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)  # Colored box \n",
        "          cv2.putText(frame, \"Frog\", (x1, y1 - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
        "        else:\n",
        "          cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 3)  # Colored box \n",
        "          cv2.putText(frame, name, (x1, y1 - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  (255, 0, 0), 2)\n",
        "\n",
        "    cv2_imshow(frame)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's go ahead and test the model! \n",
        "Please approve using the camera for the model to work.\n",
        "Once you have the video stream, click \"Capture\" to take a photo, and examine the model's output.\n",
        "Then, run the cell again and take a photo of yourself and the Jfrog frog. Did the model identify the frog?\n",
        "\n",
        "*NOTE:*\n",
        "The following cell may fail in the first time because it runs in parallel to requesting the access to the webcam. If it happens just rerun the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQfWU2oiBKoa",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    infere()\n",
        "except Exception as e:\n",
        "    cv2.destroyAllWindows()\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In case you can't or don't want to use your own picture, you can use the cheat sheet cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    infere(cheat=True)\n",
        "except Exception as e:\n",
        "    cv2.destroyAllWindows()\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qlAqOYHBKoa"
      },
      "source": [
        "# üê∏  <span style='color :#40be46' > Lab2: Securing models </span> üê∏ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNyskbpyBKoa"
      },
      "source": [
        "## Block malicious model with Xray\n",
        "\n",
        "Our Yolo model did quite well identifying human faces, but we wanted it to also detect frogs.\n",
        "What can we do?\n",
        "Searching HuggingFace, there is a model that seems just right! \n",
        "\n",
        "But is it safe? Let's configure Xray for our HuggingFace repository and find out. \n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "Let's configure Xray to scan our HuggingFaceML remote repository.\n",
        "\n",
        "#### Complete the following steps:\n",
        "\n",
        "***Add the HuggingFaceML remote repository to XRay index:***\n",
        "\n",
        "1. Navigate to *Administration --> Xray Settings --> Indexed Resources --> Repositories* and click on `+ Add a Reposotiry`\n",
        "2. Search for your repository name on the right hand side search box, and drag it to the left hand side table. Click `Save`\n",
        "3. Search for your repository in the repositories list, and click on the ... menu. Click \"Index Now\" . No need to change anything in the dialog that opens. Refresh the status to see the results.\n",
        "\n",
        "For your convenience, we've already created a policy and a watch, so just adding your repository will be enough to kick off scanning. \n",
        "You can examine them in the following links:\n",
        "\n",
        "1. Policy: https://jftrain17224572670.jfrog.io/ui/admin/xray/policiesGovernance/policies/edit/block-malicious-models\n",
        "2. Watch: https://jftrain17224572670.jfrog.io/ui/admin/xray/policiesGovernance/watches/edit/bloack-malicious-model-watch?activeTab=violations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAk8olXUBKoa",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    snapshot_download(repo_id=\"MustEr/best_model_for_identifying_frogs\")\n",
        "except HfHubHTTPError as e:\n",
        "    print(\"\\n\\n\\U0001F6A8\\U0001F6A8\\U0001F6A8\\U0001F6A8 Xray blocked model download due to violation of the 'Malicious Package' policy.\\U0001F6A8\\U0001F6A8\\U0001F6A8\\U0001F6A8\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check the scanning results \n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "Navigate to your project's scans list (**remembe to replace x with your student id**)\n",
        "\n",
        "https://jftrain17224572670.jfrog.io/ui/scans-list/repositories?projectKey=mlops-userx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJPjVasqBKoa"
      },
      "source": [
        "# üê∏  <span style='color :#40be46' > Lab3: Uploading updated model to a local repository and deploying with Qwak </span> üê∏ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USGKsStrBKob"
      },
      "source": [
        "## Train the model to identify Frogs\n",
        "\n",
        "Unfortunately, the \"best_model_for_identifying_frogs\" was not safe and we cannot use it.\n",
        "But we still want to detect the frogs. Next, we will 'train' our original Yolo model to identify other objects, specifically frogs.\n",
        "\n",
        "üëÄ  Due to time constraints, our training function does not actually train on additional images. Instead, we'll just change the model configuration. Check the \"config.json\" file before and after the training to see the difference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2xC_SQ6BKob",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "def train(object_to_detect):\n",
        "\n",
        "    if not object_to_detect in model.names.values():\n",
        "        print(f\"'{object_to_detect}' is not a valid YOLOv8 object. Hint: try Frog\")\n",
        "        return\n",
        "\n",
        "    reverse_dict = {name: idx for idx, name in model.names.items()}\n",
        "    class_id = reverse_dict.get(object_to_detect, None)\n",
        "\n",
        "    with open(config_file, 'r') as file:\n",
        "        config = json.load(file)\n",
        "\n",
        "    target_classes = config['target_classes']\n",
        "\n",
        "    # Add the new class number to the classes list if it's not already present\n",
        "    if class_id not in config['classes']:\n",
        "        config['classes'].append(class_id)\n",
        "        config['classes'].extend([cls for cls in target_classes if cls not in config['classes']])\n",
        "\n",
        "\n",
        "    # Save the updated config back to the file\n",
        "    with open(config_file, 'w') as file:\n",
        "        json.dump(config, file, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvzi83nrBKob",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "train(\"Frog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osJKMUJXBKob"
      },
      "source": [
        "## Run inference again\n",
        "\n",
        "Let's check if the training did the trick!\n",
        "Please take the JFrog frog and take a photo of the two of you together üòä üê∏ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7ZkKdhrBKob",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    infere()\n",
        "except Exception as e:\n",
        "    cv2.destroyAllWindows()\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, Cheat sheet cell is available if you like in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    infere(cheat=True)\n",
        "except Exception as e:\n",
        "    cv2.destroyAllWindows()\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j54q37oHBKob"
      },
      "source": [
        "## Upload to HF local\n",
        "\n",
        "Now that we have a new, trained model, we need to upload it to Artifactory HugginigFaceML local repository in order to share it with other teams and promote it towards Production.\n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "Please perform the following steps:\n",
        "1. Navigate to *Administration --> Repositories*.\n",
        "2. Create a **local** HuggingFaceML repository in your Artifactory project. This repository will be used to cache the models HuggingFace.\n",
        "3. Navigate to \"Application --> Artifactory --> Artifacts\" and find your newly created local repository. Click on \"Set Me Up\" and the top bar on the right.\n",
        "4. Copy the *token* and paste it in the cell below, replacing the <IDENTITY_TOKEN> placeholder\n",
        "5. Copy the HF_ENDPOINT value and paste it in the cell below, replacing the <PATH> placeholder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A580wraBKob",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Replace the <IDENTITY-TOKEN> placeholder with the token you generated in the JFrog Platform SetMeUp.\n",
        "%env HF_TOKEN=<IDENTITY-TOKEN>\n",
        "\n",
        "# Replace the <PATH> placeholder with the path to your ML Model Management repository in Artifactory, found in the JFrog Platform SetMeUp.\n",
        "%env HF_ENDPOINT=<PATH>\n",
        "\n",
        "%env HF_HUB_DOWNLOAD_TIMEOUT=86400\n",
        "%env HF_HUB_ETAG_TIMEOUT=86400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkiWAoQ2BKob",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "import os\n",
        "\n",
        "# Initialize API with the custom endpoint\n",
        "api = HfApi(endpoint=os.getenv(\"HF_ENDPOINT\"))\n",
        "\n",
        "# Upload folder to the specified repository\n",
        "api.upload_folder(\n",
        "    folder_path=\".\",\n",
        "    repo_id=\"frog-factor1\",   # Replace with a name for your model\n",
        "    repo_type=\"model\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7A30IlOBKob"
      },
      "source": [
        "### Check the results in Artifactory\n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "Let's check Artifactory to review the outcome.\n",
        "\n",
        "\n",
        "1. Please open your Artifactory instance Navigate to *Artifactory --> Artifacts* tab.\n",
        "2. Find your newly created *local HuggingFaceML repository*.\n",
        "3. Expand the repository and verify the YOLOV8 model is cached inside the repository, including the updated configuration file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytvkoKZnBKob"
      },
      "source": [
        "## Deploy with Qwak\n",
        "\n",
        "Now that we have a good model version, let's deploy it to a production endpoint with Qwak and moitor its performance.\n",
        "Qwak A fully managed end-to-end platform that contains the infrastructure AI practitioners need to build, deploy, manage and monitor GenAI, LLMs and classic ML in production.\n",
        "\n",
        "We'll start by installing the qwak SDK.\n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "1. Replace <ARTIFACTORY_PIP_REPOSITORY_URL> with the URL pointing to your pip repository found in the the JFrog Platform Set-Me-Up (you can take it from the cell in the first lab)\n",
        "2. Create a personal API key in the Qwak platform:\n",
        "    - Go to [Quak Platform](https://app.qwak.ai/)\n",
        "    - On the left hand side menu, Navigate to *Settings --> Personal API Keys*\n",
        "    - Click on `Generate API Key`\n",
        "    - Copy the API key generated and replace the below <QWAK_PERSONAL_API_KEY> placeholder with it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXA_3Xd7BKob"
      },
      "outputs": [],
      "source": [
        "# Replace <ARTIFACTORY_PIP_REPOSITORY_URL> with the URL pointing to your pip repository found in the the JFrog Platform Set-Me-Up.\n",
        "!pip3 install qwak-sdk -i <ARTIFACTORY_PIP_REPOSITORY_URL>\n",
        "# Replace <QWAK_PERSONAL_API_KEY> with your Qwak personal key from the qwak platform.\n",
        "!qwak configure --api-key <QWAK_PERSONAL_API_KEY>\n",
        "\n",
        "# Test successful connection\n",
        "!qwak projects list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFCWoxaaBKob"
      },
      "source": [
        "### Build the Qwak model\n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "In order to build and deploy the model through the Qwak platform, we'll need to first find the model-id.\n",
        "1. In the [Quak Platform](https://app.qwak.ai/) Navigate to *Models*.\n",
        "2. Select your project and click on your model.\n",
        "3. Copy your model-id from the information bar under the title with the model name (you'll have a clickable copy icon once you hover on it)\n",
        "4. Replace the <MODEL_ID> placeholder below with your model_id.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w9t_IXnBKoc"
      },
      "outputs": [],
      "source": [
        "!qwak models build --model-id yolo_test_1 ./model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSB5ey-WBKoc"
      },
      "source": [
        "### Check your model build status (can take up to 10 minutes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awRTEZCdBKoc"
      },
      "source": [
        "### Deploy your model\n",
        "\n",
        "‚ú® <span style='color : #fae253' > TASK </span> ‚ú®\n",
        "\n",
        "1. In the [Quak Platform](https://app.qwak.ai/) Navigate to *Models*.\n",
        "2. Select your project and click on your model.\n",
        "3. Under the *Builds* tab, identify your build and click `Deploy`\n",
        "4. Select `Realtime`\n",
        "5. On the next screen, no need to change anything, click on `Deploy Model`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu-Yr9yXBKoc"
      },
      "outputs": [],
      "source": [
        "models.shira-jfrog1.qwak.ai/v1/yolo_test_1/default/predict()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hf-demo-tutorial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
